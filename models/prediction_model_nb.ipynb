{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T13:16:47.886660Z",
     "start_time": "2025-04-04T13:16:47.882687Z"
    }
   },
   "source": [
    "# ================================================\n",
    "# 📦 1. Load Dependencies and Define Paths\n",
    "# ================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = \"../data/\"\n",
    "MODEL_PATH = \"../models/saved/\"\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T13:16:51.230665Z",
     "start_time": "2025-04-04T13:16:48.888491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================\n",
    "# 📂 2. Load CSV Files\n",
    "# ================================================\n",
    "players = pd.read_csv(DATA_PATH + \"players.csv\")\n",
    "transfers = pd.read_csv(DATA_PATH + \"transfers.csv\")\n",
    "player_valuations = pd.read_csv(DATA_PATH + \"player_valuations.csv\")\n",
    "appearances = pd.read_csv(DATA_PATH + \"appearances.csv\")\n",
    "clubs = pd.read_csv(DATA_PATH + \"clubs.csv\")\n",
    "competitions = pd.read_csv(DATA_PATH + \"competitions.csv\")\n",
    "games = pd.read_csv(DATA_PATH + \"games.csv\")\n"
   ],
   "id": "c7bbe02af6f92c38",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T13:16:52.414702Z",
     "start_time": "2025-04-04T13:16:52.267620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================\n",
    "# 🧹 3. Clean and Format Data\n",
    "# ================================================\n",
    "# Convert dates\n",
    "players[\"date_of_birth\"] = pd.to_datetime(players[\"date_of_birth\"], errors=\"coerce\")\n",
    "players[\"contract_expiration_date\"] = pd.to_datetime(players[\"contract_expiration_date\"], errors=\"coerce\")\n",
    "transfers[\"transfer_date\"] = pd.to_datetime(transfers[\"transfer_date\"], errors=\"coerce\")\n",
    "player_valuations[\"date\"] = pd.to_datetime(player_valuations[\"date\"], errors=\"coerce\")\n",
    "appearances[\"date\"] = pd.to_datetime(appearances[\"date\"], errors=\"coerce\")\n",
    "games[\"date\"] = pd.to_datetime(games[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Add ref_date to each transfer (1 month before the transfer)\n",
    "transfers[\"ref_date\"] = transfers[\"transfer_date\"] - pd.DateOffset(months=1)"
   ],
   "id": "18ca1938393d0a7f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T13:16:53.520309Z",
     "start_time": "2025-04-04T13:16:53.513656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================\n",
    "# 🧠 4. Enrich Club Data (Historical Value, Squad Strength)\n",
    "# ================================================\n",
    "# Compute club total market value by year (last season available before transfer)\n",
    "clubs[\"last_season\"] = pd.to_numeric(clubs[\"last_season\"], errors=\"coerce\")\n",
    "club_value_by_season = clubs.groupby([\"club_id\", \"last_season\"])[\"total_market_value\"].mean().reset_index()\n",
    "\n",
    "# Add league info to club\n",
    "clubs = clubs.merge(competitions[[\"competition_id\", \"country_name\"]],\n",
    "                    left_on=\"domestic_competition_id\",\n",
    "                    right_on=\"competition_id\", how=\"left\")"
   ],
   "id": "7c73d7ee6da1c3a0",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-04T13:17:04.217567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================\n",
    "# 🧹 5. Build Training Dataset with Player & Club Features\n",
    "# ================================================\n",
    "samples = []\n",
    "print(\"\\nBuilding dataset...\")\n",
    "for _, row in tqdm(transfers.iterrows(), total=len(transfers)):\n",
    "    pid = row[\"player_id\"]\n",
    "    to_club = row[\"to_club_id\"]\n",
    "    ref_date = row[\"ref_date\"]\n",
    "\n",
    "    p = players[players[\"player_id\"] == pid]\n",
    "    if p.empty:\n",
    "        continue\n",
    "    p = p.iloc[0]\n",
    "\n",
    "    val_hist = player_valuations[(player_valuations[\"player_id\"] == pid) &\n",
    "                                 (player_valuations[\"date\"] < ref_date)]\n",
    "    if val_hist.empty:\n",
    "        continue\n",
    "\n",
    "    # Stats\n",
    "    val_now = val_hist.sort_values(\"date\").iloc[-1][\"market_value_in_eur\"]\n",
    "    val_mean = val_hist[\"market_value_in_eur\"].mean()\n",
    "    val_growth = (val_now - val_hist.iloc[0][\"market_value_in_eur\"]) / val_hist.iloc[0][\"market_value_in_eur\"] if val_hist.iloc[0][\"market_value_in_eur\"] > 0 else 0\n",
    "\n",
    "    perf = appearances[(appearances[\"player_id\"] == pid) & (appearances[\"date\"] < ref_date)]\n",
    "    goals = perf[\"goals\"].sum()\n",
    "    assists = perf[\"assists\"].sum()\n",
    "    mins = perf[\"minutes_played\"].sum()\n",
    "    matches = perf.shape[0]\n",
    "\n",
    "    age = ref_date.year - p[\"date_of_birth\"].year if pd.notnull(p[\"date_of_birth\"]) else None\n",
    "    height_in_cm = p[\"height_in_cm\"]\n",
    "    nationality = p[\"country_of_citizenship\"]\n",
    "    pos = p[\"position\"]\n",
    "\n",
    "    # Club info\n",
    "    c = clubs[clubs[\"club_id\"] == to_club]\n",
    "    if c.empty:\n",
    "        continue\n",
    "    c = c.iloc[0]\n",
    "\n",
    "    squad_val = c[\"total_market_value\"]\n",
    "    squad_size = c[\"squad_size\"]\n",
    "    avg_age = c[\"average_age\"]\n",
    "    foreign_pct = c[\"foreigners_percentage\"]\n",
    "    nat_players = c[\"national_team_players\"]\n",
    "    net_transfers = c[\"net_transfer_record\"]\n",
    "    club_country = c[\"country_name\"]\n",
    "\n",
    "    samples.append({\n",
    "        \"player_id\": pid,\n",
    "        \"to_club_id\": to_club,\n",
    "        \"age\": age,\n",
    "        \"height_in_cm\": height_in_cm,\n",
    "        \"nationality\": nationality,\n",
    "        \"position\": pos,\n",
    "        \"market_value_now\": val_now,\n",
    "        \"market_value_mean\": val_mean,\n",
    "        \"market_value_growth\": val_growth,\n",
    "        \"goals\": goals,\n",
    "        \"assists\": assists,\n",
    "        \"minutes\": mins,\n",
    "        \"matches\": matches,\n",
    "        \"club_market_value\": squad_val,\n",
    "        \"club_squad_size\": squad_size,\n",
    "        \"club_avg_age\": avg_age,\n",
    "        \"club_foreigners_pct\": foreign_pct,\n",
    "        \"club_nat_players\": nat_players,\n",
    "        \"club_net_transfer_record\": net_transfers,\n",
    "        \"club_country\": club_country\n",
    "    })\n"
   ],
   "id": "ed661f2c371d3b6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1838/79556 [00:19<12:11, 106.23it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a487778e2b8057e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T12:38:18.442656Z",
     "start_time": "2025-04-04T12:38:18.267691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================\n",
    "# 🪼 6. Preprocess Dataset\n",
    "# ================================================\n",
    "data = pd.DataFrame(samples)\n",
    "\n",
    "# Fill missing numeric values with 0\n",
    "num_cols = [\n",
    "    \"age\", \"height_in_cm\", \"market_value_now\", \"market_value_mean\", \"market_value_growth\",\n",
    "    \"goals\", \"assists\", \"minutes\", \"matches\",\n",
    "    \"club_market_value\", \"club_squad_size\", \"club_avg_age\",\n",
    "    \"club_foreigners_pct\", \"club_nat_players\", \"club_net_transfer_record\"\n",
    "]\n",
    "data[num_cols] = data[num_cols].fillna(0)\n",
    "\n",
    "# Fill missing categoricals with 'Unknown'\n",
    "data[\"nationality\"] = data[\"nationality\"].fillna(\"Unknown\")\n",
    "data[\"position\"] = data[\"position\"].fillna(\"Unknown\")\n",
    "data[\"club_country\"] = data[\"club_country\"].fillna(\"Unknown\")\n",
    "\n",
    "# Remove rare classes with less than 2 samples\n",
    "data_counts = data[\"to_club_id\"].value_counts()\n",
    "valid_clubs = data_counts[data_counts >= 2].index\n",
    "data = data[data[\"to_club_id\"].isin(valid_clubs)]\n",
    "\n",
    "# Label encode target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data[\"club_target\"] = le.fit_transform(data[\"to_club_id\"])\n",
    "\n",
    "# Select features\n",
    "features = [\n",
    "    \"age\", \"height_in_cm\", \"market_value_now\", \"market_value_mean\", \"market_value_growth\",\n",
    "    \"goals\", \"assists\", \"minutes\", \"matches\",\n",
    "    \"club_market_value\", \"club_squad_size\", \"club_avg_age\",\n",
    "    \"club_foreigners_pct\", \"club_nat_players\", \"club_net_transfer_record\"\n",
    "]\n",
    "\n",
    "# Convert categorical to numeric via one-hot or label encoding\n",
    "data = pd.get_dummies(data, columns=[\"nationality\", \"position\", \"club_country\"], drop_first=True)\n",
    "\n",
    "# Split\n",
    "X = data.drop(columns=[\"player_id\", \"to_club_id\", \"club_target\"])\n",
    "y = data[\"club_target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)"
   ],
   "id": "982055f8b7f8ceb6",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 38\u001B[39m\n\u001B[32m     35\u001B[39m X = data.drop(columns=[\u001B[33m\"\u001B[39m\u001B[33mplayer_id\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mto_club_id\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mclub_target\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     36\u001B[39m y = data[\u001B[33m\"\u001B[39m\u001B[33mclub_target\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m X_train, X_test, y_train, y_test = \u001B[43mtrain_test_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstratify\u001B[49m\u001B[43m=\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m42\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documentos\\ESIEE\\DataScience\\data-science-project\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    212\u001B[39m         skip_parameter_validation=(\n\u001B[32m    213\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    214\u001B[39m         )\n\u001B[32m    215\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    219\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    222\u001B[39m     msg = re.sub(\n\u001B[32m    223\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    224\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    225\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    226\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documentos\\ESIEE\\DataScience\\data-science-project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2872\u001B[39m, in \u001B[36mtrain_test_split\u001B[39m\u001B[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[39m\n\u001B[32m   2868\u001B[39m         CVClass = ShuffleSplit\n\u001B[32m   2870\u001B[39m     cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state)\n\u001B[32m-> \u001B[39m\u001B[32m2872\u001B[39m     train, test = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m=\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstratify\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2874\u001B[39m train, test = ensure_common_namespace_device(arrays[\u001B[32m0\u001B[39m], train, test)\n\u001B[32m   2876\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\n\u001B[32m   2877\u001B[39m     chain.from_iterable(\n\u001B[32m   2878\u001B[39m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m arrays\n\u001B[32m   2879\u001B[39m     )\n\u001B[32m   2880\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documentos\\ESIEE\\DataScience\\data-science-project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1909\u001B[39m, in \u001B[36mBaseShuffleSplit.split\u001B[39m\u001B[34m(self, X, y, groups)\u001B[39m\n\u001B[32m   1879\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Generate indices to split data into training and test set.\u001B[39;00m\n\u001B[32m   1880\u001B[39m \n\u001B[32m   1881\u001B[39m \u001B[33;03mParameters\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1906\u001B[39m \u001B[33;03mto an integer.\u001B[39;00m\n\u001B[32m   1907\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1908\u001B[39m X, y, groups = indexable(X, y, groups)\n\u001B[32m-> \u001B[39m\u001B[32m1909\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iter_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1910\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documentos\\ESIEE\\DataScience\\data-science-project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2318\u001B[39m, in \u001B[36mStratifiedShuffleSplit._iter_indices\u001B[39m\u001B[34m(self, X, y, groups)\u001B[39m\n\u001B[32m   2316\u001B[39m class_counts = np.bincount(y_indices)\n\u001B[32m   2317\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np.min(class_counts) < \u001B[32m2\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m2318\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2319\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe least populated class in y has only 1\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2320\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m member, which is too few. The minimum\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2321\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m number of groups for any class cannot\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2322\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m be less than 2.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2323\u001B[39m     )\n\u001B[32m   2325\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n_train < n_classes:\n\u001B[32m   2326\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2327\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe train_size = \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m should be greater or \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2328\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mequal to the number of classes = \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m\"\u001B[39m % (n_train, n_classes)\n\u001B[32m   2329\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ================================================\n",
    "# 🤖 7. Train EBM Model\n",
    "# ================================================\n",
    "print(\"\\nTraining Explainable Boosting Machine (EBM)...\")\n",
    "ebm = ExplainableBoostingClassifier(interactions=10, random_state=42)\n",
    "ebm.fit(X_train, y_train)\n"
   ],
   "id": "d6e9aa117772697c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ================================================\n",
    "# 📊 8. Evaluate Model\n",
    "# ================================================\n",
    "y_pred = ebm.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ],
   "id": "13706ec8a5217dbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ================================================\n",
    "# 💾 9. Save Model and Encoder\n",
    "# ================================================\n",
    "joblib.dump(ebm, MODEL_PATH + \"ebm_club_model.pkl\")\n",
    "joblib.dump(le, MODEL_PATH + \"ebm_club_label_encoder.pkl\")\n",
    "print(\"\\nEBM model and label encoder saved successfully.\")\n"
   ],
   "id": "e6fc9bb04ba33b90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8bc5cfce4a91b27d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7bd905e86fac77ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f1c45c2d71e7f25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3427cf9beef92a51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bb720cce9bc624e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
